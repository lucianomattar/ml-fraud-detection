{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucianomattar/ml-fraud-detection/blob/main/credit%20card%20frau%20detection%20ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLladj9Oj-u6"
      },
      "source": [
        "### Machine learning for fraud detection with kaggle db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEw8rej8dFx_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from sklearn.cluster import KMeans\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbnPzvGVfTAk"
      },
      "outputs": [],
      "source": [
        "#download kaggle fraud file\n",
        "#https://drive.google.com/file/d/1s_bSWBT_e5RzfzD7-x-Db0AZByyD3Xsv/view?usp=sharing\n",
        "\n",
        "files.upload()\n",
        "df = pd.read_csv(\"creditcard.csv\") \n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe7_1i9W8tdr"
      },
      "outputs": [],
      "source": [
        "#descriptive analysis\n",
        "dfDesc = df\n",
        "\n",
        "dfDesc.describe()\n",
        "\n",
        "dfCT = dfDesc.loc[dfDesc['Time'] == dfDesc.Time.max()]\n",
        "pd.crosstab(dfCT.Time, dfCT.Class)\n",
        "\n",
        "dfCT = dfDesc.loc[dfDesc['V3'] == dfDesc.V3.max()]\n",
        "pd.crosstab(dfCT.V3, dfCT.Class)\n",
        "\n",
        "dfCT = dfDesc.loc[dfDesc['V1'] == dfDesc.V1.max()]\n",
        "pd.crosstab(dfCT.V1, dfCT.Class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWKAIS072D_g"
      },
      "outputs": [],
      "source": [
        "#Standardization\n",
        "scaler = StandardScaler()\n",
        "df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZafOT5yya5Pg"
      },
      "outputs": [],
      "source": [
        "#descriptive\n",
        "df.describe()\n",
        "\n",
        "count = df['Class'].value_counts()\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#return target variable to binary format\n",
        "df['Class'] = np.where(df['Class']>=1, 1, 0)\n",
        "\n",
        "count = df['Class'].value_counts()\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6WEkwdIiMTx"
      },
      "source": [
        "Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAp_YoHgFzYb"
      },
      "outputs": [],
      "source": [
        "#kmeans\n",
        "kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "kmeans.fit(dfDesc)\n",
        "\n",
        "np.unique(kmeans.labels_)\n",
        "\n",
        "dfDesc.loc[:,\"cluster\"] = kmeans.labels_\n",
        "\n",
        "count = dfDesc['cluster'].value_counts()\n",
        "print(count)\n",
        "\n",
        "pd.crosstab(dfDesc.Class, dfDesc.cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsI2gTLsiOZG"
      },
      "outputs": [],
      "source": [
        "#set target and features\n",
        "features=df[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
        "'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
        "'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n",
        "'Amount', 'Time']]\n",
        "target=df[['Class']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzU69fEKirn2"
      },
      "outputs": [],
      "source": [
        "#create train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target['Class'], test_size = 0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iauBuuJkiXVt"
      },
      "outputs": [],
      "source": [
        "#logistic regression\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "fit = lr.fit(X_train, y_train)\n",
        "print(fit)\n",
        "\n",
        "predict = lr.predict(X_test)\n",
        "print(predict)\n",
        "\n",
        "score = lr.score(X_test, y_test)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwxMNrVMigoO"
      },
      "outputs": [],
      "source": [
        "#Multi-layer Perceptron (MLP) \n",
        "mlp = MLPClassifier(alpha=0.001, hidden_layer_sizes=(10,), activation='relu', solver='adam', random_state=1, max_iter=1000)\n",
        "\n",
        "fit = mlp.fit(X_train, y_train)\n",
        "print(fit)\n",
        "\n",
        "mlp.predict(X_test)\n",
        "print(predict)\n",
        "\n",
        "score = mlp.score(X_test, y_test)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAuQSJIviIhy"
      },
      "source": [
        "Subsampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up4MYMbugVdl"
      },
      "outputs": [],
      "source": [
        "# finding class==1\n",
        "n_of_fraud = len (df[df.Class==1])\n",
        "fraud = np.array (df[df.Class==1].index)\n",
        "no_fraud=np.array (df[df.Class==0].index)\n",
        "\n",
        "#Select no fraud data in the same amount as fraud data\n",
        "np.random.seed(0)\n",
        "no_fraud_choice = np.random.choice(no_fraud, n_of_fraud, replace = False)\n",
        "\n",
        "#create data indices through concatenation of fraud and no fraud indices\n",
        "indx_subsampling=np.concatenate([fraud,no_fraud_choice],axis=None)\n",
        "\n",
        "#select the data through the chosen indices\n",
        "subsampling_data = df.iloc[indx_subsampling,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1azw9OtEV8Dz"
      },
      "outputs": [],
      "source": [
        "#identificando os valores de features e target para a subsampling\n",
        "features_sa=subsampling_data[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
        "'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
        "'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n",
        "'Amount', 'Time']]\n",
        "target_sa=subsampling_data[['Class']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "395zuj78gC_z"
      },
      "outputs": [],
      "source": [
        "#create train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_sa, target_sa['Class'], test_size = 0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQaGwCmGUHC9"
      },
      "outputs": [],
      "source": [
        "#counter frauds train data\n",
        "count = y_train.value_counts()\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7uSFvj8j9hM"
      },
      "outputs": [],
      "source": [
        "#logistic regression\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "fit = lr.fit(X_train, y_train)\n",
        "print(fit)\n",
        "\n",
        "predict = lr.predict(X_test)\n",
        "print(predict)\n",
        "\n",
        "score = lr.score(X_test, y_test)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i-UCATTXtrj"
      },
      "outputs": [],
      "source": [
        "#recall logistic regression\n",
        "print(classification_report(y_test, lr.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOHJJ5fvkCmv"
      },
      "outputs": [],
      "source": [
        "#Multi-layer Perceptron (MLP) \n",
        "mlp = MLPClassifier(alpha=0.001, hidden_layer_sizes=(10,), activation='relu', solver='adam', random_state=1, max_iter=3000)\n",
        "\n",
        "fit = mlp.fit(X_train, y_train)\n",
        "print(fit)\n",
        "\n",
        "mlp.predict(X_test)\n",
        "print(predict)\n",
        "\n",
        "score = mlp.score(X_test, y_test)\n",
        "print(score)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM8qj+RbksniipEf6HeCFd4",
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
